---
name: Udacity Computer Vision Nanodegree Projects
tools: [Facial Keypoint Detection, Image Captioning, SLAM, LSTMs, CNN, Computer Vision, Deep Learning]
image: https://raw.githubusercontent.com/idajana/Computer_Vision_Udacity_Nanodegree/main/Project_1_Facial_Keypoint_Detection/images/key_pts_example.png
description: Three Computer Vision projects in the scope of the Compter Vision Nanodegree offered by Udacity.
---

# Computer Vision Udacity Nanodegree

The Computer Vision Nanodegree is broken into three parts each of them concluded with a project:

1. Intro to Computer Vision - edge detection, semantic segmentation, object detection using traditional methods or by utilizing convolutional neural networks.

2. Advanced Computer Vision and Deep Learning - advanced methods such as YOLO, regin-based CNN, RNNs and combining them to create an Image captioning model.
3. Object Tracking and Localization - object motion and tracking, optical flow and feature matching, SLAM.

## Project 1: Facial Keypoint Detection


In this project,we build a facial keypoint detection system. Facial keypoints include points around the eyes, nose, and mouth on a face and are used in many applications. These applications include: facial tracking, facial pose recognition, facial filters, and emotion recognition. The code is able to look at any image, detect faces, and predict the locations of facial keypoints on each face; examples of these keypoints are displayed below.

![Facial Keypoint Detection](https://raw.githubusercontent.com/idajana/Computer_Vision_Udacity_Nanodegree/main/Project_1_Facial_Keypoint_Detection/images/key_pts_example.png)

#ä Project 2: Image Captioning
In the second project we combine LSTMs and CNNs to make an Image captioning model 
![img_capt](https://raw.githubusercontent.com/idajana/Computer_Vision_Udacity_Nanodegree/main/Project_2_Image_Captioning/images/encoder-decoder.png)

## Project 3: SLAM
In this project, we implement SLAM (Simultaneous Localization and Mapping) for a 2 dimensional world! You’ll combine what you know about robot sensor measurements and movement to create a map of an environment from only sensor and motion data gathered by a robot, over time. SLAM gives you a way to track the location of a robot in the world in real-time and identify the locations of landmarks such as buildings, trees, rocks, and other world features. This is an active area of research in the fields of robotics and autonomous systems.
![slam](https://github.com/idajana/Computer_Vision_Udacity_Nanodegree/raw/main/Project_3_SLAM/images/robot_world.png)


PROJECT CODE: [link](https://github.com/idajana/Computer_Vision_Udacity_Nanodegree) 


